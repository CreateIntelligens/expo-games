# =============================================================================
# test_emotion_api.py - æƒ…ç·’åˆ†æAPIç«¯é»æ¸¬è©¦
# =============================================================================
# æ¸¬è©¦æƒ…ç·’åˆ†æç›¸é—œçš„APIç«¯é»ï¼ŒåŒ…æ‹¬æª”æ¡ˆä¸Šå‚³ã€é è¦½åŠŸèƒ½ã€é€²åº¦æ›´æ–°ç­‰
# =============================================================================

import pytest
import asyncio
import json
import base64
import tempfile
import os
from io import BytesIO
from unittest.mock import MagicMock, patch, AsyncMock
from fastapi.testclient import TestClient
from fastapi import UploadFile
import websockets

from backend.app import app
from backend.services.emotion_service import EmotionService


class TestEmotionAPI:
    """æƒ…ç·’åˆ†æAPIæ¸¬è©¦é¡"""

    @pytest.fixture
    def client(self):
        """å»ºç«‹FastAPIæ¸¬è©¦å®¢æˆ¶ç«¯"""
        return TestClient(app)

    @pytest.fixture
    def sample_image_file(self):
        """å»ºç«‹æ¸¬è©¦ç”¨çš„åœ–ç‰‡æª”æ¡ˆ"""
        # å»ºç«‹ä¸€å€‹å°çš„æ¸¬è©¦åœ–ç‰‡
        image_data = b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x01\x00\x00\x00\x01\x08\x02\x00\x00\x00\x90wS\xde\x00\x00\x00\tpHYs\x00\x00\x0b\x13\x00\x00\x0b\x13\x01\x00\x9a\x9c\x18\x00\x00\x00\nIDATx\x9cc\xf8\x00\x00\x00\x01\x00\x01\x00\x00\x00\x00IEND\xaeB`\x82'
        return ("test_image.png", BytesIO(image_data), "image/png")

    @pytest.fixture
    def sample_video_file(self):
        """å»ºç«‹æ¸¬è©¦ç”¨çš„å½±ç‰‡æª”æ¡ˆ"""
        # å»ºç«‹ä¸€å€‹å°çš„æ¸¬è©¦å½±ç‰‡æª”æ¡ˆï¼ˆæ¨¡æ“¬ï¼‰
        video_data = b'\x00\x00\x00\x18ftypmp42\x00\x00\x00\x00mp42isom'
        return ("test_video.mp4", BytesIO(video_data), "video/mp4")

    @pytest.fixture
    def large_file(self):
        """å»ºç«‹è¶…éå¤§å°é™åˆ¶çš„æª”æ¡ˆ"""
        # å»ºç«‹ä¸€å€‹100MBçš„å¤§æª”æ¡ˆ
        large_data = b'0' * (100 * 1024 * 1024)
        return ("large_file.png", BytesIO(large_data), "image/png")

    def test_image_emotion_analysis_success(self, client, sample_image_file):
        """æ¸¬è©¦åœ–ç‰‡æƒ…ç·’åˆ†ææˆåŠŸæ¡ˆä¾‹"""
        with patch('backend.services.emotion_service.EmotionService.analyze_image_deepface') as mock_analyze:
            mock_analyze.return_value = {
                "emotion_zh": "é–‹å¿ƒ",
                "emotion_en": "happy",
                "emoji": "ğŸ˜Š",
                "confidence": 0.95,
                "face_detected": True,
                "engine": "deepface",
                "raw_scores": {
                    "happy": 0.95,
                    "sad": 0.02,
                    "neutral": 0.03
                }
            }

            filename, file_content, content_type = sample_image_file
            response = client.post(
                "/api/emotion/analyze/image",
                files={"file": (filename, file_content, content_type)}
            )

            assert response.status_code == 200
            data = response.json()
            assert data["emotion_zh"] == "é–‹å¿ƒ"
            assert data["emotion_en"] == "happy"
            assert data["emoji"] == "ğŸ˜Š"
            assert data["confidence"] == 0.95
            assert data["face_detected"] is True

    def test_image_emotion_analysis_no_file(self, client):
        """æ¸¬è©¦æœªæä¾›æª”æ¡ˆçš„æƒ…æ³"""
        response = client.post("/api/emotion/analyze/image")
        assert response.status_code == 422  # FastAPI validation error

    def test_image_emotion_analysis_invalid_format(self, client):
        """æ¸¬è©¦ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼"""
        invalid_file = ("test.txt", BytesIO(b"not an image"), "text/plain")
        filename, file_content, content_type = invalid_file

        response = client.post(
            "/api/emotion/analyze/image",
            files={"file": (filename, file_content, content_type)}
        )

        assert response.status_code == 400
        assert "åƒ…æ”¯æ´åœ–ç‰‡æ ¼å¼" in response.json()["detail"]

    def test_image_emotion_analysis_file_too_large(self, client, large_file):
        """æ¸¬è©¦æª”æ¡ˆéå¤§çš„æƒ…æ³"""
        filename, file_content, content_type = large_file

        response = client.post(
            "/api/emotion/analyze/image",
            files={"file": (filename, file_content, content_type)}
        )

        assert response.status_code == 413
        assert "æª”æ¡ˆéå¤§" in response.json()["detail"]

    def test_image_emotion_analysis_service_error(self, client, sample_image_file):
        """æ¸¬è©¦æœå‹™éŒ¯èª¤çš„æƒ…æ³"""
        with patch('backend.services.emotion_service.EmotionService.analyze_image_deepface') as mock_analyze:
            mock_analyze.side_effect = Exception("DeepFace analysis failed")

            filename, file_content, content_type = sample_image_file
            response = client.post(
                "/api/emotion/analyze/image",
                files={"file": (filename, file_content, content_type)}
            )

            assert response.status_code == 200  # è¿”å›é è¨­å€¼
            data = response.json()
            assert data["emotion_zh"] == "ä¸­æ€§"
            assert data["confidence"] == 0.0
            assert "error" in data

    def test_video_emotion_analysis_success(self, client, sample_video_file):
        """æ¸¬è©¦å½±ç‰‡æƒ…ç·’åˆ†ææˆåŠŸæ¡ˆä¾‹"""
        def mock_stream_generator(video_path, frame_interval):
            """æ¨¡æ“¬ä¸²æµåˆ†æçµæœ"""
            yield {
                "emotion_zh": "é–‹å¿ƒ",
                "emotion_en": "happy",
                "emoji": "ğŸ˜Š",
                "confidence": 0.89,
                "frame_time": 0.5,
                "progress": 25,
                "completed": False
            }
            yield {
                "emotion_zh": "æ‚²å‚·",
                "emotion_en": "sad",
                "emoji": "ğŸ˜¢",
                "confidence": 0.76,
                "frame_time": 1.0,
                "progress": 50,
                "completed": False
            }
            yield {
                "message": "å½±ç‰‡åˆ†æå®Œæˆ",
                "total_frames": 2,
                "progress": 100,
                "completed": True
            }

        with patch('backend.services.emotion_service.EmotionService.analyze_video_deepface_stream') as mock_stream:
            mock_stream.return_value = mock_stream_generator("", 0.5)

            filename, file_content, content_type = sample_video_file
            response = client.post(
                "/api/emotion/analyze/video",
                files={"file": (filename, file_content, content_type)},
                data={"frame_interval": "0.5"}
            )

            assert response.status_code == 200
            assert response.headers["content-type"] == "text/event-stream; charset=utf-8"

            # è§£æSSEæ•¸æ“š
            content = response.content.decode()
            lines = content.strip().split('\n')

            # é©—è­‰è‡³å°‘æœ‰SSEæ ¼å¼çš„æ•¸æ“š
            assert any(line.startswith("data: ") for line in lines)

    def test_video_emotion_analysis_invalid_format(self, client):
        """æ¸¬è©¦å½±ç‰‡æª”æ¡ˆæ ¼å¼éŒ¯èª¤"""
        invalid_file = ("test.txt", BytesIO(b"not a video"), "text/plain")
        filename, file_content, content_type = invalid_file

        response = client.post(
            "/api/emotion/analyze/video",
            files={"file": (filename, file_content, content_type)},
            data={"frame_interval": "0.5"}
        )

        assert response.status_code == 400
        assert "åƒ…æ”¯æ´å½±ç‰‡æ ¼å¼" in response.json()["detail"]

    def test_video_emotion_analysis_invalid_interval(self, client, sample_video_file):
        """æ¸¬è©¦ç„¡æ•ˆçš„æˆªå¹€é–“éš”"""
        filename, file_content, content_type = sample_video_file

        # æ¸¬è©¦é–“éš”éå°
        response = client.post(
            "/api/emotion/analyze/video",
            files={"file": (filename, file_content, content_type)},
            data={"frame_interval": "0.05"}
        )
        assert response.status_code == 400

        # æ¸¬è©¦é–“éš”éå¤§
        response = client.post(
            "/api/emotion/analyze/video",
            files={"file": (filename, file_content, content_type)},
            data={"frame_interval": "6.0"}
        )
        assert response.status_code == 400

    def test_video_emotion_analysis_service_error(self, client, sample_video_file):
        """æ¸¬è©¦å½±ç‰‡åˆ†ææœå‹™éŒ¯èª¤"""
        def mock_error_generator(video_path, frame_interval):
            """ç”¢ç”Ÿå™¨å‡½æ•¸ï¼Œåœ¨èª¿ç”¨æ™‚æ‹‹å‡ºç•°å¸¸"""
            if False:  # è®“ç”Ÿæˆå™¨å‡½æ•¸æœ‰yieldï¼Œä½†ä¸åŸ·è¡Œ
                yield {}
            raise Exception("Video processing failed")

        with patch('backend.services.emotion_service.EmotionService.analyze_video_deepface_stream') as mock_stream:
            mock_stream.return_value = mock_error_generator("", 0.5)

            filename, file_content, content_type = sample_video_file
            response = client.post(
                "/api/emotion/analyze/video",
                files={"file": (filename, file_content, content_type)},
                data={"frame_interval": "0.5"}
            )

            assert response.status_code == 200
            content = response.content.decode()
            assert "ä¸²æµåˆ†æéŒ¯èª¤" in content


class TestEmotionWebSocket:
    """æƒ…ç·’åˆ†æWebSocketæ¸¬è©¦é¡"""

    @pytest.fixture
    def sample_base64_image(self):
        """å»ºç«‹base64ç·¨ç¢¼çš„æ¸¬è©¦åœ–ç‰‡"""
        image_data = b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x01\x00\x00\x00\x01\x08\x02\x00\x00\x00\x90wS\xde\x00\x00\x00\tpHYs\x00\x00\x0b\x13\x00\x00\x0b\x13\x01\x00\x9a\x9c\x18\x00\x00\x00\nIDATx\x9cc\xf8\x00\x00\x00\x01\x00\x01\x00\x00\x00\x00IEND\xaeB`\x82'
        return base64.b64encode(image_data).decode()

    @pytest.mark.asyncio
    async def test_websocket_emotion_stream_success(self, sample_base64_image):
        """æ¸¬è©¦WebSocketæƒ…ç·’ä¸²æµæˆåŠŸæ¡ˆä¾‹"""
        with patch('backend.services.emotion_service.EmotionService.analyze_image_deepface') as mock_analyze:
            mock_analyze.return_value = {
                "emotion_zh": "é–‹å¿ƒ",
                "emotion_en": "happy",
                "emoji": "ğŸ˜Š",
                "confidence": 0.92,
                "face_detected": True,
                "engine": "deepface"
            }

            with TestClient(app) as client:
                with client.websocket_connect("/ws/emotion") as websocket:
                    # ç™¼é€æ¸¬è©¦å¹€
                    test_message = {
                        "type": "frame",
                        "image": f"data:image/png;base64,{sample_base64_image}",
                        "timestamp": 12345.67
                    }
                    websocket.send_json(test_message)

                    # æ¥æ”¶åˆ†æçµæœ
                    response = websocket.receive_json()

                    assert response["type"] == "result"
                    assert response["emotion_zh"] == "é–‹å¿ƒ"
                    assert response["emotion_en"] == "happy"
                    assert response["emoji"] == "ğŸ˜Š"
                    assert response["confidence"] == 0.92
                    assert response["timestamp"] == 12345.67

    @pytest.mark.asyncio
    async def test_websocket_emotion_stream_ping_pong(self):
        """æ¸¬è©¦WebSocketå¿ƒè·³åŠŸèƒ½"""
        with TestClient(app) as client:
            with client.websocket_connect("/ws/emotion") as websocket:
                # ç™¼é€pingæ¶ˆæ¯
                websocket.send_json({"type": "ping"})

                # æ¥æ”¶pongå›æ‡‰
                response = websocket.receive_text()
                assert response == "pong"

    @pytest.mark.asyncio
    async def test_websocket_emotion_stream_invalid_message_type(self):
        """æ¸¬è©¦WebSocketç„¡æ•ˆæ¶ˆæ¯é¡å‹"""
        with TestClient(app) as client:
            with client.websocket_connect("/ws/emotion") as websocket:
                # ç™¼é€ç„¡æ•ˆæ¶ˆæ¯é¡å‹
                websocket.send_json({"type": "invalid_type"})

                # æ¥æ”¶éŒ¯èª¤å›æ‡‰
                response = websocket.receive_json()
                assert response["type"] == "error"
                assert "ä¸æ”¯æŒçš„æ¶ˆæ¯é¡å‹" in response["message"]

    @pytest.mark.asyncio
    async def test_websocket_emotion_stream_analysis_error(self, sample_base64_image):
        """æ¸¬è©¦WebSocketåˆ†æéŒ¯èª¤"""
        with patch('backend.services.emotion_service.EmotionService.analyze_image_deepface') as mock_analyze:
            mock_analyze.side_effect = Exception("Analysis failed")

            with TestClient(app) as client:
                with client.websocket_connect("/ws/emotion") as websocket:
                    # ç™¼é€æ¸¬è©¦å¹€
                    test_message = {
                        "type": "frame",
                        "image": f"data:image/png;base64,{sample_base64_image}",
                        "timestamp": 12345.67
                    }
                    websocket.send_json(test_message)

                    # æ¥æ”¶éŒ¯èª¤å›æ‡‰
                    response = websocket.receive_json()

                    assert response["type"] == "error"
                    assert "å½±åƒåˆ†æéŒ¯èª¤" in response["message"]
                    assert response["timestamp"] == 12345.67


class TestFileUploadAndPreview:
    """æª”æ¡ˆä¸Šå‚³å’Œé è¦½åŠŸèƒ½æ¸¬è©¦é¡"""

    @pytest.fixture
    def client(self):
        return TestClient(app)

    def test_supported_image_formats(self, client):
        """æ¸¬è©¦æ”¯æ´çš„åœ–ç‰‡æ ¼å¼"""
        supported_formats = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']

        for ext in supported_formats:
            with patch('backend.services.emotion_service.EmotionService.analyze_image_deepface') as mock_analyze:
                mock_analyze.return_value = {
                    "emotion_zh": "ä¸­æ€§",
                    "face_detected": True,
                    "confidence": 0.5
                }

                filename = f"test{ext}"
                file_content = BytesIO(b"fake image data")

                response = client.post(
                    "/api/emotion/analyze/image",
                    files={"file": (filename, file_content, "image/jpeg")}
                )

                assert response.status_code == 200

    def test_supported_video_formats(self, client):
        """æ¸¬è©¦æ”¯æ´çš„å½±ç‰‡æ ¼å¼"""
        supported_formats = ['.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv', '.webm']

        for ext in supported_formats:
            with patch('backend.services.emotion_service.EmotionService.analyze_video_deepface_stream') as mock_stream:
                mock_stream.return_value = iter([{"completed": True}])

                filename = f"test{ext}"
                file_content = BytesIO(b"fake video data")

                response = client.post(
                    "/api/emotion/analyze/video",
                    files={"file": (filename, file_content, "video/mp4")},
                    data={"frame_interval": "0.5"}
                )

                assert response.status_code == 200

    def test_file_size_validation(self, client):
        """æ¸¬è©¦æª”æ¡ˆå¤§å°é©—è­‰"""
        # æ¸¬è©¦æ­£å¸¸å¤§å°æª”æ¡ˆ
        normal_file = ("test.png", BytesIO(b"small image"), "image/png")
        with patch('backend.services.emotion_service.EmotionService.analyze_image_deepface') as mock_analyze:
            mock_analyze.return_value = {"emotion_zh": "ä¸­æ€§", "face_detected": True}

            filename, file_content, content_type = normal_file
            response = client.post(
                "/api/emotion/analyze/image",
                files={"file": (filename, file_content, content_type)}
            )
            assert response.status_code == 200


class TestProgressAndStatusUpdates:
    """é€²åº¦æ¢å’Œç‹€æ…‹æ›´æ–°æ¸¬è©¦é¡"""

    @pytest.fixture
    def client(self):
        return TestClient(app)

    def test_upload_progress_simulation(self, client):
        """æ¸¬è©¦ä¸Šå‚³é€²åº¦æ¨¡æ“¬"""
        # é€™å€‹æ¸¬è©¦é©—è­‰APIèƒ½æ­£ç¢ºè™•ç†æª”æ¡ˆä¸Šå‚³
        image_file = ("progress_test.png", BytesIO(b"test data for progress"), "image/png")

        with patch('backend.services.emotion_service.EmotionService.analyze_image_deepface') as mock_analyze:
            mock_analyze.return_value = {
                "emotion_zh": "é–‹å¿ƒ",
                "confidence": 0.85,
                "face_detected": True
            }

            filename, file_content, content_type = image_file
            response = client.post(
                "/api/emotion/analyze/image",
                files={"file": (filename, file_content, content_type)}
            )

            assert response.status_code == 200
            # é©—è­‰èƒ½å¤ æˆåŠŸå®Œæˆæ•´å€‹åˆ†ææµç¨‹
            data = response.json()
            assert "emotion_zh" in data
            assert "confidence" in data

    def test_video_stream_progress_tracking(self, client):
        """æ¸¬è©¦å½±ç‰‡ä¸²æµé€²åº¦è¿½è¹¤"""
        def mock_progress_stream(video_path, frame_interval):
            # æ¨¡æ“¬æœ‰é€²åº¦è³‡è¨Šçš„ä¸²æµ
            for i, progress in enumerate([25, 50, 75, 100]):
                yield {
                    "emotion_zh": "é–‹å¿ƒ",
                    "frame_time": i * 0.5,
                    "progress": progress,
                    "completed": progress == 100
                }

        with patch('backend.services.emotion_service.EmotionService.analyze_video_deepface_stream') as mock_stream:
            mock_stream.return_value = mock_progress_stream("", 0.5)

            video_file = ("progress_video.mp4", BytesIO(b"fake video"), "video/mp4")
            filename, file_content, content_type = video_file

            response = client.post(
                "/api/emotion/analyze/video",
                files={"file": (filename, file_content, content_type)},
                data={"frame_interval": "0.5"}
            )

            assert response.status_code == 200
            # é©—è­‰SSEå›æ‡‰åŒ…å«é€²åº¦è³‡è¨Š
            content = response.content.decode()
            assert "progress" in content
            assert "completed" in content

    def test_status_message_sequence(self, client):
        """æ¸¬è©¦ç‹€æ…‹æ¶ˆæ¯åºåˆ—"""
        # é©—è­‰APIè¿”å›çš„ç‹€æ…‹æ¶ˆæ¯åŒ…å«å¿…è¦è³‡è¨Š
        image_file = ("status_test.png", BytesIO(b"status test data"), "image/png")

        with patch('backend.services.emotion_service.EmotionService.analyze_image_deepface') as mock_analyze:
            # æ¨¡æ“¬åˆ†æéç¨‹
            mock_analyze.return_value = {
                "emotion_zh": "é©šè¨",
                "emotion_en": "surprise",
                "emoji": "ğŸ˜²",
                "confidence": 0.78,
                "face_detected": True,
                "engine": "deepface"
            }

            filename, file_content, content_type = image_file
            response = client.post(
                "/api/emotion/analyze/image",
                files={"file": (filename, file_content, content_type)}
            )

            assert response.status_code == 200
            data = response.json()

            # é©—è­‰å›æ‡‰åŒ…å«å®Œæ•´çš„ç‹€æ…‹è³‡è¨Š
            required_fields = ["emotion_zh", "emotion_en", "emoji", "confidence", "face_detected"]
            for field in required_fields:
                assert field in data, f"Missing required field: {field}"


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
