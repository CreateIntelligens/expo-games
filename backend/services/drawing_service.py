# =============================================================================
# drawing_service.py - AI ç•«å¸ƒè­˜åˆ¥æœå‹™
# åŸºæ–¼ MediaPipe å’Œæ‰‹å‹¢è¿½è¹¤çš„è™›æ“¬ç¹ªç•«å’Œ AI åœ–åƒè­˜åˆ¥ç³»çµ±
# =============================================================================

import logging
import threading
import time
from collections import deque
from enum import Enum
from typing import Dict, List, Optional, Tuple, Union
import base64
import io
from types import SimpleNamespace

import cv2
import numpy as np
from PIL import Image, ImageDraw

from ..utils.gpu_runtime import configure_gpu_runtime

_GPU_STATUS = configure_gpu_runtime()

try:
    import mediapipe as mp
    _MEDIAPIPE_AVAILABLE = True
    _MEDIAPIPE_ERROR: Optional[str] = None
except Exception as exc:
    mp = SimpleNamespace(solutions=SimpleNamespace(hands=None))
    _MEDIAPIPE_AVAILABLE = False
    _MEDIAPIPE_ERROR = str(exc)

from .status_broadcaster import StatusBroadcaster
from ..utils.datetime_utils import _now_ts
from ..utils.hand_tracking_module import HandTrackingModule, GestureResult, GestureType
from ..utils.drawing_engine import DrawingEngine, BrushType

# WebSocket æ”¯æ´
import asyncio
import json
from typing import Set
from fastapi import WebSocket, WebSocketDisconnect


logger = logging.getLogger(__name__)

if _GPU_STATUS.warnings:
    for warning in _GPU_STATUS.warnings:
        logger.warning("GPU setup warning: %s", warning)
else:
    logger.info(
        "DrawingService GPU ready | TensorFlow devices: %s | MediaPipe GPU enabled: %s",
        _GPU_STATUS.tensorflow_devices,
        _GPU_STATUS.mediapipe_gpu_enabled,
    )


class DrawingMode(Enum):
    """ç¹ªç•«æ¨¡å¼"""
    INDEX_FINGER = "index_finger"  # é£ŸæŒ‡ç¹ªç•«
    BOTH_FINGERS = "both_fingers"  # é›™æŒ‡æ§åˆ¶
    GESTURE_CONTROL = "gesture_control"  # æ‰‹å‹¢æ§åˆ¶


class DrawingColor(Enum):
    """ç¹ªç•«é¡è‰²"""
    BLACK = (0, 0, 0)
    RED = (0, 0, 255)
    GREEN = (0, 255, 0)
    BLUE = (255, 0, 0)
    YELLOW = (0, 255, 255)
    PURPLE = (255, 0, 255)
    CYAN = (255, 255, 0)
    WHITE = (255, 255, 255)


class DrawingAction(Enum):
    """ç¹ªç•«å‹•ä½œ"""
    DRAW = "draw"
    ERASE = "erase"
    CLEAR = "clear"
    SAVE = "save"


class FingerTracker:
    """æ‰‹æŒ‡è¿½è¹¤å™¨ï¼ŒåŸºæ–¼ MediaPipe Hands"""

    def __init__(self):
        self.mediapipe_ready = _MEDIAPIPE_AVAILABLE
        self.init_error: Optional[str] = _MEDIAPIPE_ERROR
        self.hands = None

        if self.mediapipe_ready:
            try:
                self.mp_hands = mp.solutions.hands
                self.mp_drawing = mp.solutions.drawing_utils
                self.hands = self.mp_hands.Hands(
                    static_image_mode=False,
                    max_num_hands=1,
                    min_detection_confidence=0.6,  # å¹³è¡¡æº–ç¢ºåº¦å’Œæ•æ„Ÿåº¦
                    min_tracking_confidence=0.5,   # ç©©å®šçš„è¿½è¹¤
                    model_complexity=1             # ä½¿ç”¨ä¸­ç­‰æ¨¡å‹ï¼Œå¹³è¡¡é€Ÿåº¦å’Œæº–ç¢ºåº¦
                )
                logger.info("MediaPipe Hands åˆå§‹åŒ–å®Œæˆï¼Œå•Ÿç”¨æ‰‹æŒ‡è¿½è¹¤")
            except Exception as exc:
                self.mediapipe_ready = False
                self.init_error = str(exc)
                logger.exception("åˆå§‹åŒ– MediaPipe Hands å¤±æ•—: %s", exc)
        else:
            logger.warning("MediaPipe Hands ç„¡æ³•ä½¿ç”¨: %s", self.init_error)

    def is_available(self) -> bool:
        """å›å‚³ MediaPipe æ˜¯å¦å¯ç”¨"""
        return self.mediapipe_ready and self.hands is not None

    def get_finger_positions(self, frame) -> Dict:
        """ç²å–æ‰‹æŒ‡ä½ç½®"""
        if frame is None or not self.is_available():
            return {}

        height, width, _ = frame.shape
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.hands.process(frame_rgb)

        if not results.multi_hand_landmarks:
            return {}

        # ç²å–ç¬¬ä¸€éš»æ‰‹çš„é—œéµé»
        hand_landmarks = results.multi_hand_landmarks[0]

        # é‡è¦æ‰‹æŒ‡é—œéµé»ç´¢å¼•
        finger_tips = {
            'thumb': 4,      # æ‹‡æŒ‡
            'index': 8,      # é£ŸæŒ‡
            'middle': 12,    # ä¸­æŒ‡
            'ring': 16,      # ç„¡åæŒ‡
            'pinky': 20      # å°æŒ‡
        }

        finger_positions = {}
        for finger, tip_idx in finger_tips.items():
            landmark = hand_landmarks.landmark[tip_idx]
            x = int(landmark.x * width)
            y = int(landmark.y * height)
            finger_positions[finger] = (x, y)

        # è¨ˆç®—æ‰‹æŒ‡æ˜¯å¦ä¼¸ç›´ (ç”¨æ–¼æ‰‹å‹¢æ§åˆ¶)
        fingers_up = self._get_fingers_up(hand_landmarks)
        finger_positions['fingers_up'] = fingers_up

        return finger_positions

    def _get_fingers_up(self, hand_landmarks) -> List[bool]:
        """æª¢æ¸¬å“ªäº›æ‰‹æŒ‡æ˜¯ä¼¸ç›´çš„

        ç­–ç•¥ï¼š
        - æ‹‡æŒ‡æ°¸é å›å‚³ Falseï¼ˆå¿½ç•¥æ‹‡æŒ‡åˆ¤å®šï¼Œé¿å…èª¤åˆ¤ï¼‰
        - é£ŸæŒ‡åˆ¤å®šé©ä¸­ï¼ˆæ–¹ä¾¿ç¹ªç•«ï¼‰
        - å…¶ä»–æ‰‹æŒ‡åˆ¤å®šåš´æ ¼ï¼ˆç¢ºä¿åªæœ‰é£ŸæŒ‡ä¼¸ç›´æ™‚æ‰ç¹ªç•«ï¼‰
        - ä½¿ç”¨ä¸‰é»åˆ¤æ–·é¿å…èƒŒæ™¯å¹²æ“¾
        """
        fingers = []

        # æ‹‡æŒ‡ - ç›´æ¥å¿½ç•¥ï¼Œæ°¸é å›å‚³ False
        fingers.append(False)

        # é£ŸæŒ‡ (ä½¿ç”¨ä¸‰é»åˆ¤æ–·)
        index_tip = hand_landmarks.landmark[8]
        index_pip = hand_landmarks.landmark[6]
        index_mcp = hand_landmarks.landmark[5]

        # é£ŸæŒ‡åˆ¤å®šï¼štip é«˜æ–¼ PIPï¼Œä¸” PIP é«˜æ–¼æˆ–æ¥è¿‘ MCP
        index_extended = (index_tip.y < index_pip.y - 0.01) and (index_pip.y < index_mcp.y + 0.02)
        fingers.append(index_extended)

        # ä¸­æŒ‡ã€ç„¡åæŒ‡ã€å°æŒ‡ (ä½¿ç”¨é©ä¸­çš„ä¸‰é»åˆ¤æ–·)
        other_fingers = [
            (12, 10, 9),   # ä¸­æŒ‡: tip, pip, mcp
            (16, 14, 13),  # ç„¡åæŒ‡
            (20, 18, 17)   # å°æŒ‡
        ]

        for tip_idx, pip_idx, mcp_idx in other_fingers:
            tip = hand_landmarks.landmark[tip_idx]
            pip = hand_landmarks.landmark[pip_idx]
            mcp = hand_landmarks.landmark[mcp_idx]

            # é©ä¸­åˆ¤å®šï¼šæ¯”é£ŸæŒ‡åš´æ ¼ä¸€é»ï¼Œä½†ä¸è¦å¤ªåš´æ ¼
            is_extended = (tip.y < pip.y - 0.02) and (pip.y < mcp.y + 0.01)
            fingers.append(is_extended)

        return fingers


class VirtualCanvas:
    """è™›æ“¬ç•«å¸ƒ"""

    def __init__(self, width: int = 640, height: int = 480):
        self.width = width
        self.height = height
        # åˆå§‹åŒ–ç‚ºé€æ˜èƒŒæ™¯çš„RGBAç•«å¸ƒ
        self.canvas = np.zeros((height, width, 4), dtype=np.uint8)
        self.drawing_points = deque(maxlen=1000)  # æœ€è¿‘1000å€‹ç¹ªç•«é»
        self.current_color = DrawingColor.BLACK.value
        self.brush_size = 5
        self.is_drawing = False
        self.last_position = None

    @property
    def _color_with_alpha(self) -> Tuple[int, int, int, int]:
        """å°‡ç•¶å‰é¡è‰²è½‰æ›ç‚ºå« alpha çš„ BGRA é¡è‰²ã€‚"""

        if len(self.current_color) == 4:
            return self.current_color
        return (*self.current_color, 255)

    def clear_canvas(self):
        """æ¸…ç©ºç•«å¸ƒ"""
        # æ¸…ç©ºç‚ºé€æ˜èƒŒæ™¯ï¼ˆRGBAï¼‰
        self.canvas = np.zeros((self.height, self.width, 4), dtype=np.uint8)
        self.drawing_points.clear()
        self.last_position = None

    def set_color(self, color: DrawingColor):
        """è¨­ç½®ç¹ªç•«é¡è‰²"""
        self.current_color = color.value

    def set_brush_size(self, size: int):
        """è¨­ç½®ç­†åˆ·å¤§å°"""
        self.brush_size = max(1, min(20, size))

    def draw_point(self, position: Tuple[int, int], action: DrawingAction = DrawingAction.DRAW):
        """åœ¨æŒ‡å®šä½ç½®ç¹ªç•«"""
        x, y = position

        # é‚Šç•Œæª¢æŸ¥
        if not (0 <= x < self.width and 0 <= y < self.height):
            return

        if action == DrawingAction.DRAW:
            if self.last_position is not None:
                # ç•«ç·šé€£æ¥å…©é»
                cv2.line(self.canvas, self.last_position, (x, y), self._color_with_alpha, self.brush_size)
            else:
                # ç•«é»
                cv2.circle(self.canvas, (x, y), self.brush_size // 2, self._color_with_alpha, -1)

            self.drawing_points.append({
                'position': (x, y),
                'color': self.current_color,
                'size': self.brush_size,
                'timestamp': time.time()
            })

        elif action == DrawingAction.ERASE:
            # æ©¡çš®æ“¦æ•ˆæœ
            cv2.circle(self.canvas, (x, y), self.brush_size * 2, (0, 0, 0, 0), -1)

        self.last_position = (x, y)

    def stop_drawing(self):
        """åœæ­¢ç¹ªç•«ï¼ˆæŠ¬ç­†ï¼‰"""
        self.last_position = None

    def get_canvas_image(self) -> np.ndarray:
        """ç²å–ç•¶å‰ç•«å¸ƒåœ–åƒ"""
        return self.canvas.copy()

    def get_canvas_base64(self) -> str:
        """ç²å–ç•«å¸ƒçš„ base64 ç·¨ç¢¼ï¼ˆå·¦å³åè½‰ä»¥ç¬¦åˆä½¿ç”¨è€…è¦–è§’ï¼‰"""
        # å°æ–¼RGBA canvasï¼Œç›´æ¥å‰µå»ºPIL Image
        if self.canvas.shape[2] == 4:  # RGBA
            # å°‡BGRAè½‰æ›ç‚ºRGBAï¼ˆOpenCVä½¿ç”¨BGRAï¼ŒPILä½¿ç”¨RGBAï¼‰
            rgba_canvas = cv2.cvtColor(self.canvas, cv2.COLOR_BGRA2RGBA)
            pil_image = Image.fromarray(rgba_canvas, mode='RGBA')
        else:  # RGB
            pil_image = Image.fromarray(cv2.cvtColor(self.canvas, cv2.COLOR_BGR2RGB), mode='RGB')

        # å·¦å³åè½‰ç•«å¸ƒï¼Œä½¿å…¶ç¬¦åˆé¡åƒæ”å½±æ©Ÿçš„è¦–è§’
        pil_image = pil_image.transpose(Image.FLIP_LEFT_RIGHT)

        # è½‰æ›ç‚º base64
        buffered = io.BytesIO()
        pil_image.save(buffered, format="PNG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode()

        return f"data:image/png;base64,{img_base64}"


class ShapeRecognizer:
    """å½¢ç‹€è­˜åˆ¥å™¨ï¼ˆåŸºæ–¼è¼ªå»“åˆ†æï¼‰"""

    def __init__(self):
        self.shape_templates = {
            'circle': self._create_circle_template(),
            'square': self._create_square_template(),
            'triangle': self._create_triangle_template(),
            'line': self._create_line_template(),
            'heart': self._create_heart_template()
        }

    def recognize_drawing(self, canvas: np.ndarray) -> Dict:
        """è­˜åˆ¥ç•«å¸ƒä¸Šçš„åœ–å½¢"""
        # è½‰ç‚ºç°åº¦åœ–ï¼Œæ”¯æ´ BGRA/BGR
        if canvas.ndim == 3 and canvas.shape[2] == 4:
            gray = cv2.cvtColor(canvas, cv2.COLOR_BGRA2GRAY)
        else:
            gray = cv2.cvtColor(canvas, cv2.COLOR_BGR2GRAY)

        # äºŒå€¼åŒ–
        _, binary = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)

        # æ‰¾è¼ªå»“
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if not contours:
            return {
                'recognized': 'empty',
                'confidence': 1.0,
                'message': 'ç•«å¸ƒæ˜¯ç©ºçš„',
                'suggestions': ['ç•«ä¸€å€‹åœ“å½¢', 'ç•«ä¸€å€‹æ­£æ–¹å½¢', 'ç•«ä¸€æ¢ç·š']
            }

        # æ‰¾åˆ°æœ€å¤§è¼ªå»“
        largest_contour = max(contours, key=cv2.contourArea)

        # åˆ†æå½¢ç‹€ç‰¹å¾µ
        features = self._analyze_shape_features(largest_contour)

        # åŒ¹é…å½¢ç‹€
        recognized_shape, confidence = self._match_shape(features)

        return {
            'recognized': recognized_shape,
            'confidence': confidence,
            'message': self._get_recognition_message(recognized_shape, confidence),
            'features': features,
            'suggestions': self._get_suggestions(recognized_shape)
        }

    def _analyze_shape_features(self, contour) -> Dict:
        """åˆ†æå½¢ç‹€ç‰¹å¾µ"""
        area = cv2.contourArea(contour)
        perimeter = cv2.arcLength(contour, True)

        if perimeter == 0:
            return {'area': area, 'perimeter': perimeter, 'circularity': 0}

        # åœ“å½¢åº¦
        circularity = 4 * np.pi * area / (perimeter * perimeter)

        # è¿‘ä¼¼å¤šé‚Šå½¢
        epsilon = 0.02 * perimeter
        approx = cv2.approxPolyDP(contour, epsilon, True)
        vertex_count = len(approx)

        # é‚Šç•Œæ¡†
        x, y, w, h = cv2.boundingRect(contour)
        aspect_ratio = w / h if h > 0 else 0

        # å‡¸åŒ…
        hull = cv2.convexHull(contour)
        hull_area = cv2.contourArea(hull)
        solidity = area / hull_area if hull_area > 0 else 0

        return {
            'area': area,
            'perimeter': perimeter,
            'circularity': circularity,
            'vertex_count': vertex_count,
            'aspect_ratio': aspect_ratio,
            'solidity': solidity
        }

    def _match_shape(self, features: Dict) -> Tuple[str, float]:
        """æ ¹æ“šç‰¹å¾µåŒ¹é…å½¢ç‹€"""
        circularity = features['circularity']
        vertex_count = features['vertex_count']
        aspect_ratio = features['aspect_ratio']
        solidity = features['solidity']

        # åœ“å½¢æª¢æ¸¬
        if circularity > 0.7 and vertex_count > 8:
            return 'circle', min(0.95, circularity)

        # æ­£æ–¹å½¢æª¢æ¸¬
        if (vertex_count == 4 and
            0.8 < aspect_ratio < 1.2 and
            solidity > 0.8):
            return 'square', 0.85

        # ä¸‰è§’å½¢æª¢æ¸¬
        if vertex_count == 3 and solidity > 0.7:
            return 'triangle', 0.80

        # ç›´ç·šæª¢æ¸¬
        if (vertex_count == 2 or
            (aspect_ratio > 4 or aspect_ratio < 0.25)):
            return 'line', 0.75

        # å¿ƒå½¢æª¢æ¸¬ï¼ˆåŸºæ–¼è¤‡é›œåº¦ï¼‰
        if (circularity < 0.5 and
            vertex_count > 10 and
            solidity < 0.8):
            return 'heart', 0.60

        # æœªçŸ¥å½¢ç‹€
        return 'unknown', 0.3

    def _get_recognition_message(self, shape: str, confidence: float) -> str:
        """ç²å–è­˜åˆ¥çµæœè¨Šæ¯"""
        messages = {
            'circle': 'æˆ‘çœ‹åˆ°ä¸€å€‹åœ“å½¢ï¼',
            'square': 'é€™æ˜¯ä¸€å€‹æ­£æ–¹å½¢ï¼',
            'triangle': 'æˆ‘è­˜åˆ¥å‡ºä¸€å€‹ä¸‰è§’å½¢ï¼',
            'line': 'é€™æ˜¯ä¸€æ¢ç›´ç·šï¼',
            'heart': 'çœ‹èµ·ä¾†åƒä¸€å€‹å¿ƒå½¢ï¼',
            'unknown': 'æˆ‘ä¸ç¢ºå®šé€™æ˜¯ä»€éº¼å½¢ç‹€...'
        }

        base_message = messages.get(shape, 'æœªçŸ¥å½¢ç‹€')

        if confidence > 0.8:
            return f"{base_message} (éå¸¸ç¢ºå®š)"
        elif confidence > 0.6:
            return f"{base_message} (é‚„ç®—ç¢ºå®š)"
        else:
            return f"{base_message} (ä¸å¤ªç¢ºå®š)"

    def _get_suggestions(self, shape: str) -> List[str]:
        """ç²å–å»ºè­°"""
        suggestions_map = {
            'circle': ['è©¦è©¦ç•«ä¸€å€‹æ­£æ–¹å½¢', 'ç•«ä¸€æ¢ç›´ç·š', 'ç•«å€‹å¿ƒå½¢'],
            'square': ['è©¦è©¦ç•«ä¸€å€‹åœ“å½¢', 'ç•«ä¸€å€‹ä¸‰è§’å½¢', 'ç•«æ¢å°è§’ç·š'],
            'triangle': ['ç•«ä¸€å€‹åœ“å½¢', 'ç•«ä¸€å€‹æ­£æ–¹å½¢', 'ç•«å€‹æ˜Ÿæ˜Ÿ'],
            'line': ['ç•«ä¸€å€‹åœ“å½¢', 'ç•«å¹¾æ¢ç·šçµ„æˆåœ–å½¢', 'è©¦è©¦æ›²ç·š'],
            'heart': ['ç•«ä¸€å€‹åœ“å½¢', 'ç•«ä¸€å€‹ç¬‘è‡‰', 'ç•«æœµèŠ±'],
            'unknown': ['è©¦è©¦ç•«ç°¡å–®çš„å¹¾ä½•åœ–å½¢', 'ç•«ä¸€å€‹åœ“å½¢', 'ç•«ä¸€æ¢ç›´ç·š'],
            'empty': ['é–‹å§‹ç•«ç•«å§ï¼', 'è©¦è©¦ç•«ä¸€å€‹åœ“å½¢', 'ç•«ä½ å–œæ­¡çš„ä»»ä½•æ±è¥¿']
        }

        return suggestions_map.get(shape, ['ç¹¼çºŒå‰µä½œï¼'])

    def _create_circle_template(self) -> np.ndarray:
        """å‰µå»ºåœ“å½¢æ¨¡æ¿"""
        template = np.zeros((100, 100), dtype=np.uint8)
        cv2.circle(template, (50, 50), 40, 255, 2)
        return template

    def _create_square_template(self) -> np.ndarray:
        """å‰µå»ºæ­£æ–¹å½¢æ¨¡æ¿"""
        template = np.zeros((100, 100), dtype=np.uint8)
        cv2.rectangle(template, (20, 20), (80, 80), 255, 2)
        return template

    def _create_triangle_template(self) -> np.ndarray:
        """å‰µå»ºä¸‰è§’å½¢æ¨¡æ¿"""
        template = np.zeros((100, 100), dtype=np.uint8)
        points = np.array([[50, 20], [20, 80], [80, 80]], np.int32)
        cv2.polylines(template, [points], True, 255, 2)
        return template

    def _create_line_template(self) -> np.ndarray:
        """å‰µå»ºç›´ç·šæ¨¡æ¿"""
        template = np.zeros((100, 100), dtype=np.uint8)
        cv2.line(template, (20, 50), (80, 50), 255, 2)
        return template

    def _create_heart_template(self) -> np.ndarray:
        """å‰µå»ºå¿ƒå½¢æ¨¡æ¿"""
        template = np.zeros((100, 100), dtype=np.uint8)
        # ç°¡åŒ–çš„å¿ƒå½¢ï¼ˆå…©å€‹åœ“åŠ ä¸€å€‹ä¸‰è§’å½¢ï¼‰
        cv2.circle(template, (35, 35), 15, 255, 2)
        cv2.circle(template, (65, 35), 15, 255, 2)
        points = np.array([[25, 45], [75, 45], [50, 75]], np.int32)
        cv2.polylines(template, [points], True, 255, 2)
        return template


class DrawingService:
    """AI ç•«å¸ƒè­˜åˆ¥æœå‹™ä¸»é¡"""

    def __init__(self, status_broadcaster: StatusBroadcaster):
        self.status_broadcaster = status_broadcaster
        self.finger_tracker = FingerTracker()
        self.virtual_canvas = VirtualCanvas()
        self.ai_recognizer = ShapeRecognizer()

        if not self.finger_tracker.is_available():
            logger.error(
                "MediaPipe Hands æœªå•Ÿç”¨ï¼Œæ‰‹æŒ‡è¿½è¹¤åŠŸèƒ½å°‡ä¸å¯ç”¨: %s",
                self.finger_tracker.init_error,
            )

        # æœå‹™ç‹€æ…‹
        self.is_drawing = False
        self.drawing_thread = None
        self.camera = None

        # ç¹ªç•«è¨­å®š
        self.drawing_mode = DrawingMode.INDEX_FINGER
        self.current_color = DrawingColor.BLACK
        self.auto_recognize = True
        self.recognition_interval = 3  # æ¯3ç§’è‡ªå‹•è­˜åˆ¥ä¸€æ¬¡

        # çµ±è¨ˆ
        self.drawing_start_time = None
        self.total_strokes = 0
        self.recognition_history = []

        # è¦–è¦ºç©©å®šæ€§æ§åˆ¶
        self.last_canvas_update_time = 0
        self.canvas_update_interval = 0.1  # æœ€å°‘é–“éš”100msæ›´æ–°ä¸€æ¬¡ç•«å¸ƒ
        self.last_stable_gesture = "none"

        # ç•«å¸ƒå°ºå¯¸ï¼ˆé è¨­å€¼ï¼Œæœƒåœ¨é–‹å§‹æœƒè©±æ™‚æ›´æ–°ï¼‰
        self.canvas_width = 640
        self.canvas_height = 480

        # é¡è‰²é¸æ“‡å€åŸŸé…ç½®ï¼ˆ4ç¨®é¡è‰²å‡åˆ†ç•«é¢å¯¬åº¦ï¼‰
        self.color_zones = ['black', 'red', 'blue', 'green']

    def start_drawing_session(self,
                            mode: str = "index_finger",
                            color: str = "black",
                            auto_recognize: bool = True,
                            websocket_mode: bool = False) -> Dict:
        """é–‹å§‹ç¹ªç•«æœƒè©±"""
        if not self.finger_tracker.is_available():
            error_msg = self.finger_tracker.init_error or "MediaPipe Hands åˆå§‹åŒ–å¤±æ•—"
            return {
                "status": "error",
                "message": f"ç„¡æ³•å•Ÿå‹•ç¹ªç•«åŠŸèƒ½: {error_msg}",
            }

        if self.is_drawing:
            return {"status": "error", "message": "ç¹ªç•«æœƒè©±å·²åœ¨é€²è¡Œä¸­"}

        try:
            # è¨­å®šåƒæ•¸
            self.drawing_mode = DrawingMode(mode)
            self.current_color = DrawingColor[color.upper()]
            self.auto_recognize = auto_recognize

            # WebSocket æ¨¡å¼ä¸éœ€è¦é–‹å•Ÿæ”å½±æ©Ÿ
            if not websocket_mode:
                # é–‹å•Ÿæ”å½±æ©Ÿ
                self.camera = cv2.VideoCapture(0)
                if not self.camera.isOpened():
                    return {"status": "error", "message": "ç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿ"}

                self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                self.camera.set(cv2.CAP_PROP_FPS, 30)

                # é–‹å§‹ç¹ªç•«ç·šç¨‹
                self.drawing_thread = threading.Thread(
                    target=self._drawing_loop,
                    daemon=True
                )
                self.drawing_thread.start()

            # é‡ç½®ç‹€æ…‹
            self.virtual_canvas.clear_canvas()
            self.virtual_canvas.set_color(self.current_color)
            self.drawing_start_time = time.time()
            self.total_strokes = 0
            self.recognition_history = []

            # è¨­ç½®ç¹ªç•«ç‹€æ…‹
            self.is_drawing = True

            # å»£æ’­é–‹å§‹ç‹€æ…‹
            self.status_broadcaster.broadcast_threadsafe({
                "channel": "drawing",
                "stage": "started",
                "message": "AI ç•«å¸ƒæœƒè©±å·²é–‹å§‹",
                "data": {
                    "mode": mode,
                    "color": color,
                    "auto_recognize": auto_recognize,
                    "websocket_mode": websocket_mode,
                    "start_time": self.drawing_start_time
                }
            })

            return {
                "status": "started",
                "message": "ç¹ªç•«æœƒè©±å·²é–‹å§‹",
                "mode": mode,
                "color": color,
                "websocket_mode": websocket_mode
            }

        except Exception as exc:
            self.is_drawing = False
            return {"status": "error", "message": f"å•Ÿå‹•å¤±æ•—: {str(exc)}"}

    def stop_drawing_session(self) -> Dict:
        """åœæ­¢ç¹ªç•«æœƒè©±"""
        if not self.is_drawing:
            return {"status": "idle", "message": "ç¹ªç•«æœƒè©±æœªåœ¨é€²è¡Œä¸­"}

        self.is_drawing = False

        if self.camera:
            self.camera.release()
            self.camera = None

        if self.drawing_thread:
            self.drawing_thread.join(timeout=2)

        # æœ€çµ‚è­˜åˆ¥
        final_recognition = self.ai_recognizer.recognize_drawing(self.virtual_canvas.get_canvas_image())
        total_time = time.time() - self.drawing_start_time if self.drawing_start_time else 0

        # å»£æ’­åœæ­¢ç‹€æ…‹
        self.status_broadcaster.broadcast_threadsafe({
            "channel": "drawing",
            "stage": "stopped",
            "message": "ç¹ªç•«æœƒè©±å·²åœæ­¢",
            "data": {
                "total_time": total_time,
                "total_strokes": self.total_strokes,
                "final_recognition": final_recognition,
                "canvas_image": self.virtual_canvas.get_canvas_base64()
            }
        })

        return {
            "status": "stopped",
            "message": "ç¹ªç•«æœƒè©±å·²åœæ­¢",
            "final_recognition": final_recognition
        }

    def get_drawing_status(self) -> Dict:
        """ç²å–ç¹ªç•«ç‹€æ…‹"""
        if not self.is_drawing:
            return {
                "status": "idle",
                "message": "ç¹ªç•«æœƒè©±æœªåœ¨é€²è¡Œä¸­",
                "is_drawing": False
            }

        current_time = time.time()
        drawing_duration = current_time - self.drawing_start_time if self.drawing_start_time else 0

        return {
            "status": "drawing",
            "message": "ç¹ªç•«æœƒè©±é€²è¡Œä¸­",
            "is_drawing": True,
            "drawing_duration": drawing_duration,
            "total_strokes": self.total_strokes,
            "current_mode": self.drawing_mode.value,
            "current_color": self.current_color.name.lower(),
            "canvas_image": self.virtual_canvas.get_canvas_base64(),
            "recent_recognitions": self.recognition_history[-3:]  # æœ€è¿‘3æ¬¡è­˜åˆ¥
        }

    def recognize_current_drawing(self) -> Dict:
        """æ‰‹å‹•è­˜åˆ¥ç•¶å‰ç¹ªç•«"""
        recognition_result = self.ai_recognizer.recognize_drawing(self.virtual_canvas.get_canvas_image())

        # è¨˜éŒ„è­˜åˆ¥æ­·å²
        self.recognition_history.append({
            "timestamp": _now_ts(),
            "result": recognition_result
        })

        return recognition_result

    def clear_canvas(self) -> Dict:
        """æ¸…ç©ºç•«å¸ƒ"""
        self.virtual_canvas.clear_canvas()
        self.total_strokes = 0

        self.status_broadcaster.broadcast_threadsafe({
            "channel": "drawing",
            "stage": "canvas_cleared",
            "message": "ç•«å¸ƒå·²æ¸…ç©º",
            "data": {"canvas_image": self.virtual_canvas.get_canvas_base64()}
        })

        return {"status": "success", "message": "ç•«å¸ƒå·²æ¸…ç©º"}

    def change_drawing_color(self, color: str) -> Dict:
        """è®Šæ›´ç¹ªç•«é¡è‰²"""
        try:
            # é©—è­‰é¡è‰²
            valid_colors = ["black", "red", "green", "blue", "yellow", "purple", "cyan", "white"]
            if color not in valid_colors:
                return {
                    "status": "error",
                    "message": f"ç„¡æ•ˆçš„é¡è‰²: {color}ï¼Œæ”¯æ´çš„é¡è‰²: {', '.join(valid_colors)}"
                }

            # è¨­ç½®æ–°é¡è‰²
            self.current_color = DrawingColor[color.upper()]
            self.virtual_canvas.set_color(self.current_color)

            self.status_broadcaster.broadcast_threadsafe({
                "channel": "drawing",
                "stage": "color_changed",
                "message": f"ç¹ªç•«é¡è‰²å·²æ›´æ”¹ç‚º {color}",
                "data": {"new_color": color}
            })

            return {
                "status": "success",
                "message": f"ç¹ªç•«é¡è‰²å·²æ›´æ”¹ç‚º {color}",
                "color": color
            }

        except Exception as e:
            return {
                "status": "error",
                "message": f"é¡è‰²è®Šæ›´å¤±æ•—: {str(e)}"
            }

    def process_frame_for_gesture_drawing(self, frame_data: bytes, mode: str = "gesture_control") -> Dict:
        """è™•ç†å–®ä¸€å¹€ç”¨æ–¼æ‰‹å‹¢ç¹ªç•«ï¼ˆWebSocketæ¨¡å¼ï¼‰

        æ¥æ”¶å‰ç«¯ç™¼é€çš„å½±åƒå¹€ï¼Œé€²è¡Œæ‰‹å‹¢è­˜åˆ¥å’Œç¹ªç•«è™•ç†ï¼Œè¿”å›è™•ç†çµæœã€‚

        Args:
            frame_data (bytes): JPEG ç·¨ç¢¼çš„å½±åƒå¹€æ•¸æ“š
            mode (str): ç¹ªç•«æ¨¡å¼ ("gesture_control", "index_finger")

        Returns:
            Dict: è™•ç†çµæœï¼ŒåŒ…å«æ‰‹å‹¢ç‹€æ…‹ã€ç•«å¸ƒæ›´æ–°å’Œè­˜åˆ¥çµæœ
        """
        try:
            # å°‡ bytes è½‰æ›ç‚º numpy array
            nparr = np.frombuffer(frame_data, np.uint8)
            frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

            if frame is None:
                return {
                    "type": "error",
                    "message": "ç„¡æ³•è§£ç¢¼å½±åƒå¹€",
                    "timestamp": time.time()
                }

            # ç¿»è½‰é¡åƒæ•ˆæœï¼ˆèˆ‡æ”å½±æ©Ÿé è¦½ä¸€è‡´ï¼‰
            frame = cv2.flip(frame, 1)

            # æ›´æ–°ç•«å¸ƒå°ºå¯¸
            self.canvas_height, self.canvas_width = frame.shape[:2]

            # ç²å–æ‰‹æŒ‡ä½ç½®
            finger_positions = self.finger_tracker.get_finger_positions(frame)

            # è™•ç†ç¹ªç•«è¼¸å…¥
            gesture_info = self._process_gesture_drawing_frame(finger_positions, mode)

            # æª¢æŸ¥æ˜¯å¦éœ€è¦é€²è¡Œ AI è­˜åˆ¥
            recognition_result = None
            if self.auto_recognize and self.total_strokes > 0 and self.total_strokes % 50 == 0:  # æ¯50ç­†åŠƒæª¢æŸ¥ä¸€æ¬¡
                recognition_result = self.recognize_current_drawing()

            # æº–å‚™å›æ‡‰æ•¸æ“š
            current_time = time.time()
            gesture_name = gesture_info["gesture"]

            response = {
                "type": "gesture_status",
                "current_gesture": gesture_name,
                "fingers_up": finger_positions.get('fingers_up', [False] * 5) if finger_positions else [False] * 5,
                "drawing_position": gesture_info.get("position"),
                "timestamp": current_time
            }

            # å¦‚æœæœ‰ç¹ªç•«ç™¼ç”Ÿï¼Œç«‹å³æ›´æ–°ç•«å¸ƒï¼ˆç§»é™¤ç¯€æµä»¥ç¢ºä¿å³æ™‚æ€§ï¼‰
            if gesture_info["drawing_occurred"]:
                response.update({
                    "canvas_base64": self.virtual_canvas.get_canvas_base64(),
                    "stroke_count": self.total_strokes,
                    "current_color": self.current_color.name.lower()
                })

            # å¦‚æœæ˜¯é¡è‰²é¸æ“‡æ‰‹å‹¢ï¼Œé¡å¤–ç™¼é€é¡è‰²è®Šæ›´é€šçŸ¥
            if gesture_name == "color_selecting" and "selected_color" in gesture_info:
                response.update({
                    "color_changed": True,
                    "new_color": gesture_info["selected_color"],
                    "current_color": self.current_color.name.lower()
                })
                logger.info(f"âœ… ç™¼é€é¡è‰²è®Šæ›´é€šçŸ¥: {gesture_info['selected_color']}")

            # å¦‚æœæ˜¯æ¸…ç©ºæ‰‹å‹¢ï¼Œé¡å¤–ç™¼é€æ¸…ç©ºé€šçŸ¥
            if gesture_name == "clearing":
                response.update({
                    "canvas_cleared": True,
                    "canvas_base64": self.virtual_canvas.get_canvas_base64()
                })
                logger.info("âœ… ç™¼é€ç•«å¸ƒæ¸…ç©ºé€šçŸ¥")

            # å¦‚æœæœ‰è­˜åˆ¥çµæœï¼ŒåŒ…å«è­˜åˆ¥ä¿¡æ¯
            if recognition_result:
                response.update({
                    "type": "recognition_result",
                    "recognized_shape": recognition_result["recognized"],
                    "confidence": recognition_result["confidence"],
                    "message": recognition_result["message"]
                })

            return response

        except Exception as exc:
            logger.exception("è™•ç†æ‰‹å‹¢ç¹ªç•«å¹€æ™‚ç™¼ç”ŸéŒ¯èª¤: %s", exc)
            return {
                "type": "error",
                "message": f"å¹€è™•ç†éŒ¯èª¤: {str(exc)}",
                "timestamp": time.time()
            }

    def change_drawing_color(self, color_name: str) -> Dict:
        """è®Šæ›´ç¹ªç•«é¡è‰²"""
        try:
            # é©—è­‰é¡è‰²åç¨±
            color_name = color_name.upper()
            if not hasattr(DrawingColor, color_name):
                return {
                    "type": "error",
                    "message": f"ä¸æ”¯æŒçš„é¡è‰²: {color_name}",
                    "timestamp": time.time()
                }

            # è¨­ç½®æ–°é¡è‰²
            self.current_color = DrawingColor[color_name]
            self.virtual_canvas.set_color(self.current_color)

            logger.info("ç¹ªç•«é¡è‰²å·²è®Šæ›´ç‚º: %s", color_name)

            return {
                "type": "color_changed",
                "color": color_name.lower(),
                "message": f"é¡è‰²å·²è®Šæ›´ç‚º {color_name.lower()}",
                "timestamp": time.time()
            }

        except Exception as exc:
            logger.exception("è®Šæ›´é¡è‰²æ™‚ç™¼ç”ŸéŒ¯èª¤: %s", exc)
            return {
                "type": "error",
                "message": f"é¡è‰²è®Šæ›´å¤±æ•—: {str(exc)}",
                "timestamp": time.time()
            }

    def change_brush_size(self, size: int) -> Dict:
        """è®Šæ›´ç­†åˆ·å¤§å°"""
        try:
            # é©—è­‰ç­†åˆ·å¤§å°
            size = max(1, min(50, size))  # é™åˆ¶åœ¨1-50ä¹‹é–“

            # è¨­ç½®æ–°ç­†åˆ·å¤§å°
            self.virtual_canvas.set_brush_size(size)

            logger.info("ç­†åˆ·å¤§å°å·²è®Šæ›´ç‚º: %d", size)

            return {
                "type": "brush_size_changed",
                "size": size,
                "message": f"ç­†åˆ·å¤§å°å·²è®Šæ›´ç‚º {size}",
                "timestamp": time.time()
            }

        except Exception as exc:
            logger.exception("è®Šæ›´ç­†åˆ·å¤§å°æ™‚ç™¼ç”ŸéŒ¯èª¤: %s", exc)
            return {
                "type": "error",
                "message": f"ç­†åˆ·å¤§å°è®Šæ›´å¤±æ•—: {str(exc)}",
                "timestamp": time.time()
            }

    def _detect_color_from_position(self, x_pos: int) -> str:
        """æ ¹æ“š x åº§æ¨™åˆ¤æ–·é¸æ“‡çš„é¡è‰²

        Args:
            x_pos: æ‰‹æŒ‡çš„ x åº§æ¨™

        Returns:
            str: é¡è‰²åç¨±
        """
        zone_width = self.canvas_width / len(self.color_zones)
        color_index = int(x_pos / zone_width)
        color_index = max(0, min(color_index, len(self.color_zones) - 1))
        return self.color_zones[color_index]

    def _process_gesture_drawing_frame(self, finger_positions: Dict, mode: str) -> Dict:
        """è™•ç†å–®ä¸€å¹€çš„æ‰‹å‹¢ç¹ªç•«é‚è¼¯"""
        gesture_info = {
            "gesture": "no_hand",
            "drawing_occurred": False,
            "position": None
        }

        if not finger_positions:
            # æ²’æœ‰æª¢æ¸¬åˆ°æ‰‹ï¼Œåœæ­¢ç¹ªç•«
            self.virtual_canvas.stop_drawing()
            return gesture_info

        fingers_up = finger_positions.get('fingers_up', [False] * 5)
        fingers_count = sum(fingers_up)
        index_pos = finger_positions.get('index')

        if mode == "gesture_control":
            # Debug: å°å‡ºæ‰‹å‹¢åˆ¤å®šè³‡è¨Š
            logger.info(f"ğŸ‘† æ‰‹å‹¢åˆ¤å®š - fingers_up: {fingers_up}, count: {fingers_count}, index_pos: {index_pos}")

            if fingers_count == 1 and fingers_up[1] and index_pos:  # åªæœ‰é£ŸæŒ‡ - ç¹ªç•«
                self.virtual_canvas.draw_point(index_pos, DrawingAction.DRAW)
                self.total_strokes += 1
                gesture_info.update({
                    "gesture": "drawing",
                    "drawing_occurred": True,
                    "position": index_pos
                })
                logger.info(f"âœï¸ ç¹ªç•«å‹•ä½œç¢ºèª - ä½ç½®: {index_pos}")

            elif fingers_count == 2 and fingers_up[1] and fingers_up[2] and index_pos:  # é£ŸæŒ‡+ä¸­æŒ‡ - é¸æ“‡æ¨¡å¼
                middle_pos = finger_positions.get('middle')
                logger.info(f"ğŸ–ï¸ é›™æŒ‡åµæ¸¬ - index_pos: {index_pos}, middle_pos: {middle_pos}")

                if middle_pos:
                    # è¨ˆç®—é£ŸæŒ‡å’Œä¸­æŒ‡çš„ä¸­é»ä½ç½®
                    selection_pos = ((index_pos[0] + middle_pos[0]) // 2,
                                    (index_pos[1] + middle_pos[1]) // 2)

                    # æª¢æŸ¥æ˜¯å¦åœ¨é¡è‰²é¸æ“‡å€åŸŸï¼ˆç•«é¢é ‚éƒ¨ 15%ï¼‰
                    color_zone_height = int(self.canvas_height * 0.15)
                    logger.info(f"ğŸ¨ é¸æ“‡ä½ç½®: {selection_pos}, é¡è‰²å€é«˜åº¦: {color_zone_height}, canvasé«˜åº¦: {self.canvas_height}")

                    if selection_pos[1] < color_zone_height:
                        # åœ¨é¡è‰²é¸æ“‡å€åŸŸ - æ ¹æ“š x åº§æ¨™åˆ¤æ–·é¸æ“‡å“ªå€‹é¡è‰²
                        selected_color = self._detect_color_from_position(selection_pos[0])
                        if selected_color != self.current_color.name.lower():
                            self.current_color = DrawingColor[selected_color.upper()]
                            self.virtual_canvas.set_color(self.current_color)
                            gesture_info.update({
                                "gesture": "color_selecting",
                                "selected_color": selected_color,
                                "position": selection_pos
                            })
                            logger.info(f"ğŸ¨ é¡è‰²å·²åˆ‡æ›: {selected_color}")
                        else:
                            gesture_info.update({
                                "gesture": "selecting",
                                "position": selection_pos
                            })
                    else:
                        # åœ¨ç•«å¸ƒå€åŸŸ - æ©¡çš®æ“¦åŠŸèƒ½
                        self.virtual_canvas.draw_point(index_pos, DrawingAction.ERASE)
                        gesture_info.update({
                            "gesture": "erasing",
                            "drawing_occurred": True,
                            "position": index_pos
                        })
                else:
                    # æ²’æœ‰ä¸­æŒ‡ä½ç½®ï¼Œé è¨­ç‚ºæ©¡çš®æ“¦
                    self.virtual_canvas.draw_point(index_pos, DrawingAction.ERASE)
                    gesture_info.update({
                        "gesture": "erasing",
                        "drawing_occurred": True,
                        "position": index_pos
                    })

            elif fingers_count == 4:  # å››æŒ‡å…¨é–‹ï¼ˆå¿½ç•¥æ‹‡æŒ‡ï¼‰- æ¸…ç©º
                self.virtual_canvas.clear_canvas()
                self.total_strokes = 0
                gesture_info.update({
                    "gesture": "clearing",
                    "drawing_occurred": True
                })

            else:
                # å…¶ä»–æ‰‹å‹¢æˆ–ç„¡æ•ˆæ‰‹å‹¢ï¼Œåœæ­¢ç¹ªç•«
                self.virtual_canvas.stop_drawing()
                gesture_info["gesture"] = "idle"

        elif mode == "index_finger":
            if fingers_up[1] and not fingers_up[2] and index_pos:  # é£ŸæŒ‡ç¹ªç•«ï¼Œä¸­æŒ‡ä¸ä¼¸ç›´
                self.virtual_canvas.draw_point(index_pos, DrawingAction.DRAW)
                self.total_strokes += 1
                gesture_info.update({
                    "gesture": "drawing",
                    "drawing_occurred": True,
                    "position": index_pos
                })
            else:
                self.virtual_canvas.stop_drawing()
                gesture_info["gesture"] = "idle"

        return gesture_info

    def _drawing_loop(self):
        """ç¹ªç•«ä¸»å¾ªç’°"""
        last_recognition_time = 0
        frame_count = 0

        try:
            while self.is_drawing and self.camera and self.camera.isOpened():
                ret, frame = self.camera.read()
                if not ret:
                    break

                frame_count += 1

                # ç¿»è½‰é¡åƒæ•ˆæœ
                frame = cv2.flip(frame, 1)

                # ç²å–æ‰‹æŒ‡ä½ç½®
                finger_positions = self.finger_tracker.get_finger_positions(frame)

                if finger_positions and 'index' in finger_positions:
                    # æ ¹æ“šæ¨¡å¼è™•ç†ç¹ªç•«
                    self._process_drawing_input(finger_positions)
                else:
                    # æ²’æœ‰æª¢æ¸¬åˆ°æ‰‹ï¼Œåœæ­¢ç¹ªç•«
                    self.virtual_canvas.stop_drawing()

                # å®šæœŸè‡ªå‹•è­˜åˆ¥
                current_time = time.time()
                if (self.auto_recognize and
                    current_time - last_recognition_time >= self.recognition_interval):

                    recognition_result = self.recognize_current_drawing()

                    # å»£æ’­è­˜åˆ¥çµæœ
                    self.status_broadcaster.broadcast_threadsafe({
                        "channel": "drawing",
                        "stage": "recognition_update",
                        "message": recognition_result['message'],
                        "data": {
                            "recognition": recognition_result,
                            "canvas_image": self.virtual_canvas.get_canvas_base64(),
                            "drawing_duration": current_time - self.drawing_start_time
                        }
                    })

                    last_recognition_time = current_time

                # æ§åˆ¶å¹€ç‡
                time.sleep(1/30)

        except Exception as exc:
            self.status_broadcaster.broadcast_threadsafe({
                "channel": "drawing",
                "stage": "error",
                "message": f"ç¹ªç•«éŒ¯èª¤: {str(exc)}"
            })
        finally:
            if self.camera:
                self.camera.release()
                self.camera = None

            if self.is_drawing:
                self.stop_drawing_session()

    def _process_drawing_input(self, finger_positions: Dict):
        """è™•ç†ç¹ªç•«è¼¸å…¥"""
        if self.drawing_mode == DrawingMode.INDEX_FINGER:
            self._process_index_finger_drawing(finger_positions)
        elif self.drawing_mode == DrawingMode.GESTURE_CONTROL:
            self._process_gesture_control_drawing(finger_positions)

    def _process_index_finger_drawing(self, finger_positions: Dict):
        """é£ŸæŒ‡ç¹ªç•«æ¨¡å¼"""
        index_pos = finger_positions['index']
        fingers_up = finger_positions.get('fingers_up', [False] * 5)

        # åªæœ‰é£ŸæŒ‡ä¼¸ç›´æ™‚æ‰ç¹ªç•«
        if fingers_up[1] and not fingers_up[2]:  # é£ŸæŒ‡ä¼¸ç›´ï¼Œä¸­æŒ‡ä¸ä¼¸ç›´
            self.virtual_canvas.draw_point(index_pos, DrawingAction.DRAW)
            self.total_strokes += 1
        else:
            self.virtual_canvas.stop_drawing()

    def _process_gesture_control_drawing(self, finger_positions: Dict):
        """æ‰‹å‹¢æ§åˆ¶ç¹ªç•«æ¨¡å¼"""
        index_pos = finger_positions['index']
        fingers_up = finger_positions.get('fingers_up', [False] * 5)
        fingers_count = sum(fingers_up)

        if fingers_count == 1 and fingers_up[1]:  # åªæœ‰é£ŸæŒ‡
            self.virtual_canvas.draw_point(index_pos, DrawingAction.DRAW)
            self.total_strokes += 1
        elif fingers_count == 2 and fingers_up[1] and fingers_up[2]:  # é£ŸæŒ‡å’Œä¸­æŒ‡
            self.virtual_canvas.draw_point(index_pos, DrawingAction.ERASE)
        elif fingers_count == 5:  # æ‰€æœ‰æ‰‹æŒ‡ä¼¸ç›´
            self.virtual_canvas.clear_canvas()
            self.total_strokes = 0
        else:
            self.virtual_canvas.stop_drawing()


__all__ = ["DrawingService", "DrawingMode", "DrawingColor"]
